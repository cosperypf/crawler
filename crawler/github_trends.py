import requests
import re
import os
import datetime
import pandas as pd
from bs4 import BeautifulSoup

# ä¿å­˜è·¯å¾„
BASE_PATH = "./generate_docs/github_trends"
os.makedirs(BASE_PATH, exist_ok=True)

# è·å–å½“å‰æ—¥æœŸ
TODAY = datetime.datetime.today().strftime("%Y%m%d")

# AIå…³é”®è¯åˆ—è¡¨ï¼ˆå¯æ‰©å±•ï¼‰
AI_KEYWORDS = ['ai', 'artificial intelligence', 'machine learning', 'deep learning',
               'neural', 'nlp', 'transformer', 'llm', 'chatgpt', 'gpt']

# GitHub Trending æ—¶é—´ç»´åº¦
TRENDS = {
    "daily": "ä»Šæ—¥",
    "weekly": "è¿‘7æ—¥",
    "monthly": "è¿‘30æ—¥"
}


def parse_star_count(star_str):
    """å°† GitHub star æ•°æ ¼å¼å¦‚ '3.5k' è½¬ä¸ºæ•´æ•°"""
    star_str = star_str.strip().lower().replace(',', '')
    if 'k' in star_str:
        return int(float(star_str.replace('k', '')) * 1000)
    elif 'm' in star_str:
        return int(float(star_str.replace('m', '')) * 1000000)
    return int(star_str)


def fetch_trending(since='daily'):
    url = f"https://github.com/trending?since={since}&spoken_language_code=en"
    headers = {'User-Agent': 'Mozilla/5.0'}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')

    articles = soup.find_all('article', class_='Box-row')
    result = []

    for article in articles:
        # è·å– repo åç§°
        header = article.h2
        if not header:
            continue

        repo_link = header.find('a')
        if not repo_link:
            continue

        repo = repo_link.get('href').strip('/')  # /owner/repo => owner/repo
        author, name = repo.split('/')

        # è·å–æè¿°
        desc_tag = article.find('p')
        description = desc_tag.get_text(strip=True) if desc_tag else ""

        # è·å– star æ•°
        star_tag = article.find('a', href=lambda x: x and x.endswith('/stargazers'))
        stars = parse_star_count(star_tag.text.strip()) if star_tag else 0

        full_url = f"https://github.com/{repo}"
        result.append({
            "repository": repo,
            "author": author,
            "name": name,
            "description": description,
            "url": full_url,
            "stars": stars
        })

    return result


def is_ai_project(description):
    desc = description.lower()
    return any(keyword in desc for keyword in AI_KEYWORDS)


def save_to_csv_md(data_by_trend):
    csv_rows = []
    md_lines = ["# ğŸ“Š GitHub AI é¡¹ç›®è¶‹åŠ¿æ±‡æ€»ï¼ˆ" + TODAY + "ï¼‰\n"]

    for trend_key, trend_label in TRENDS.items():
        data = data_by_trend.get(trend_key, [])
        if not data:
            continue

        md_lines.append(f"## â­ {trend_label}è¶‹åŠ¿\n")
        md_lines.append("| é¡¹ç›® | â­Stars | æè¿° | é“¾æ¥ |")
        md_lines.append("|------|---------|------|------|")

        for row in data:
            csv_rows.append({
                "è¶‹åŠ¿": trend_label,
                "é¡¹ç›®": row["repository"],
                "Stars": row["stars"],
                "æè¿°": row["description"],
                "é“¾æ¥": row["url"]
            })
            md_lines.append(
                f"| `{row['repository']}` | {row['stars']} | {row['description'] or 'æ— '} | [ğŸ”—é“¾æ¥]({row['url']}) |"
            )

        md_lines.append("\n")

    # ä¿å­˜ CSV
    csv_path = os.path.join(BASE_PATH, f"github_trends_{TODAY}.csv")
    df = pd.DataFrame(csv_rows)
    df.to_csv(csv_path, index=False)
    print(f"âœ… å·²ä¿å­˜ CSVï¼š{csv_path}")

    # # ä¿å­˜ Markdown
    # md_path = os.path.join(BASE_PATH, f"github_trends_{TODAY}.md")
    # with open(md_path, "w", encoding="utf-8") as f:
    #     f.write("\n".join(md_lines))
    # print(f"âœ… å·²ä¿å­˜ MDï¼š{md_path}")


def main():
    print("ğŸ“¡ æ­£åœ¨æŠ“å– GitHub Trending é¡µé¢...")
    data_by_trend = {}

    for trend_key in TRENDS.keys():
        trending = fetch_trending(trend_key)
        ai_related = [r for r in trending if is_ai_project(r['description'])]
        # æŒ‰ stars æ’åº
        ai_related.sort(key=lambda r: r.get("stars", 0), reverse=True)
        data_by_trend[trend_key] = ai_related
        print(f"ğŸ§  {TRENDS[trend_key]}ï¼šå…±å‘ç° AI é¡¹ç›® {len(ai_related)} ä¸ª")

    save_to_csv_md(data_by_trend)


if __name__ == "__main__":
    main()