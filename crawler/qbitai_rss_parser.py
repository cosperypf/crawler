import feedparser
from datetime import datetime
import csv
import os
from html import unescape
import re

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹è§£æé‡å­ä½ RSS...")
    # ========== è®¾ç½®è·¯å¾„ ==========
    output_dir = "./generate_docs/qbitai"
    os.makedirs(output_dir, exist_ok=True)
    csv_filename = f"qbitai_{datetime.now().strftime('%Y%m%d')}.csv"
    output_path = os.path.join(output_dir, csv_filename)

    # ========== è§£æ RSS ==========
    RSS_URL = "https://www.qbitai.com/feed"
    feed = feedparser.parse(RSS_URL)

    def clean_html(text):
        text = unescape(text)
        text = re.sub(r'<.*?>', '', text)
        return text.strip()

    articles = []
    for entry in feed.entries:
        title = entry.title.strip()
        link = entry.link
        published = entry.published

        # æå–ä½œè€…ä¿¡æ¯
        if "dc_creator" in entry:
            authors = entry.dc_creator
        else:
            authors = "Qbitai"

        # æå–æè¿°
        description = clean_html(entry.description)

        # æå–åˆ†ç±»æ ‡ç­¾
        if "tags" in entry:
            categories = ", ".join(tag.term for tag in entry.tags)
        elif "category" in entry:
            categories = entry.category
        else:
            categories = "AIèµ„è®¯"

        articles.append({
            "Date": published,
            "Title": title,
            "Authors": authors,
            "Categories": categories,
            "Description": description,
            "Link": link
        })

    # ========== å†™å…¥ CSV ==========
    with open(output_path, mode='w', newline='', encoding='utf-8') as csvfile:
        fieldnames = ["Date", "Title", "Authors", "Categories", "Description", "Link"]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for article in articles:
            writer.writerow(article)

    print(f"âœ… é‡å­ä½èµ„è®¯å·²ä¿å­˜è‡³ï¼š{output_path}")